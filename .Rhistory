skes<-ske(x)
p.val1l[i]<-as.numeric(skes<sn[1])
p.val1r[i]<-as.numeric(skes>sn[2])
p.val2l[i]<-as.numeric(skes<bb[1])
p.val2r[i]<-as.numeric(skes>bb[2])
p.val3l[i]<-as.numeric(skes<pb[1])
p.val3r[i]<-as.numeric(skes>pb[2])
p.val1[i]<-1-(p.val1l[i]+p.val1r[i])
p.val2[i]<-1-(p.val2l[i]+p.val2r[i])
p.val3[i]<-1-(p.val3l[i]+p.val3r[i])
}
print(c(mean(p.val1l),mean(p.val2l),mean(p.val3l)))
print(c(mean(p.val1r),mean(p.val2r),mean(p.val3r)))
print(c(mean(p.val1),mean(p.val2),mean(p.val3)))
set.seed(1)
nn<-1e3
x<-cbind(c(rchisq(nn,df=5),rchisq(nn,df=5)))
obj <- boot::boot(data=x,statistic=b.skewness,R=2000)
round(c(original=obj$t0,bias=mean(obj$t)-obj$t0,
se=sd(obj$t)),3)
alpha<-c(.025,.975)
#standard normal bootstrap confidence interval
sn<-obj$t0+qnorm(alpha)*sd(obj$t)
print(sn)
#basic bootstrap confidence interval
bb<-2*obj$t0-quantile(obj$t,rev(alpha),type = 1)
print(bb)
#percentile bootstrap confidence interval
pb<-quantile(obj$t,alpha,type=6)
print(pb)
set.seed(1)
m<-1e3
p.val1<-p.val2<-p.val3<-numeric(m)
p.val1l<-p.val2l<-p.val3l<-numeric(m)
p.val1r<-p.val2r<-p.val3r<-numeric(m)
for(i in 1:m)
{
x<-rchisq(nn,df=5)
skes<-ske(x)
p.val1l[i]<-as.numeric(skes<sn[1])
p.val1r[i]<-as.numeric(skes>sn[2])
p.val2l[i]<-as.numeric(skes<bb[1])
p.val2r[i]<-as.numeric(skes>bb[2])
p.val3l[i]<-as.numeric(skes<pb[1])
p.val3r[i]<-as.numeric(skes>pb[2])
p.val1[i]<-1-(p.val1l[i]+p.val1r[i])
p.val2[i]<-1-(p.val2l[i]+p.val2r[i])
p.val3[i]<-1-(p.val3l[i]+p.val3r[i])
}
print(c(mean(p.val1l),mean(p.val2l),mean(p.val3l)))
print(c(mean(p.val1r),mean(p.val2r),mean(p.val3r)))
print(c(mean(p.val1),mean(p.val2),mean(p.val3)))
set.seed(0)
n<-20
R<-9999
#library(MASS)
reps<-numeric(R)
x<-rnorm(n)
y<-rnorm(n)
t0<-cor(x,y)
z<-c(x,y)
K<-1:20
for(i in 1:R){
k<-sample(K,size=n,replace = FALSE)
x1<-z[k]
y1<-z[-k]
reps[i]<-cor(x1,y1,method = "spearman")
}
p<-mean(abs(c(t0,reps))>=abs(t0))
round(c(p,cor.test(x,y)$p.value),3)
#library(RANN)
#library(energy)
#library(Ball)
#library(boot)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- RANN::nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
m <- 50; k<-3; p<-2; mu <- 0.3; set.seed(12345)
n1 <- n2 <- 50; R<-999; n <- n1+n2; N = c(n1,n2)
eqdist.nn <- function(z,sizes,k){
boot.obj <- boot::boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
set.seed(1235)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0,1.37),ncol=p);
y <- cbind(rnorm(n2),rnorm(n2));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- energy::eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- Ball::bd.test(x=x,y=y,num.permutations=999,seed=i*12)$p.value
}
alpha <- 0.1;
pow <- colMeans(p.values<alpha)
print(pow)
set.seed(12455)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0.1,1.37),ncol=p);
y <- cbind(rnorm(n2),rnorm(n2));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- energy::eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- Ball::bd.test(x=x,y=y,num.permutations=999,seed=i*123)$p.value
}
alpha <- 0.1;
pow <- colMeans(p.values<alpha)
print(pow)
set.seed(12455)
for(i in 1:m){
x <- matrix(rt(n1*p,1),ncol=p);
y1 <- rnorm(n1*p,0,1);
y2 <- rnorm(n1*p,1,2.8);
r<-sample(c(0,1),n1*p,replace = TRUE)
y0<-r*y1+(1-r)*y2
y<-matrix(y0,ncol = p)
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- energy::eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- Ball::bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow <- colMeans(p.values<alpha)
print(pow)
m <- 1e2; k<-3; p<-2; mu <- 0.3; set.seed(12345)
n1 <-10; n2 <- 90; R<-999; n <- n1+n2; N = c(n1,n2)
eqdist.nn <- function(z,sizes,k){
boot.obj <- boot::boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0,1.55),ncol=p);
y <- cbind(rnorm(n2),rnorm(n2));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- energy::eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- Ball::bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow <- colMeans(p.values<alpha)
print(pow)
f<-function(x,theta=1,eta=0){
stopifnot(theta>0)
return(1/(theta*pi*(1+((x-eta)/theta)^2)))
}
set.seed(1)
m  <-  10000
sigma  <-2.7
x  <-  numeric(m)
x[1]  <-  rnorm(1,mean=0,sd=sigma)
#x[1]<-5
k  <-  0
u  <-  runif(m)
for  (i  in  2:m)  {
xt  <-  x[i-1]
y  <-  rnorm(1,mean=xt,sd=sigma)
num <- f(y) * dnorm(xt, mean=y,sd = sigma)
den <- f(xt) * dnorm(y,mean=xt ,sd=sigma)
if  (u[i]  <= num/den ) x[i]  <-  y  else  {
x[i]  <-  xt
k  <-  k+1         #y  is  rejected
}
}
index <- 5000:5500
y1 <- x[index]
plot(index, y1, type="l", main="", ylab="x")
###  compare the deciles of the generated observations
###  with the deciles of the standard Cauchy distribution
b <- 1001 #discard the burnin sample
y <- x[b:m]
a <- ppoints(10)
QR <- qt(a,df=1) #quantiles of Cauchy
Q <- quantile(x, a)
qqplot(QR, Q, main="",
xlab="Cauchy Quantiles", ylab="Sample Quantiles")
qqline(Q)
hist(y, breaks="scott", main="", xlab="", freq=FALSE)
lines(QR, f(QR, theta = 1,eta=0))
Gelman.Rubin <- function(psi) {
# psi[i,j] is the statistic psi(X[i,1:j])
# for chain in i-th row of X
psi <- as.matrix(psi)
n <- ncol(psi)
k <- nrow(psi)
psi.means <- rowMeans(psi) #row means
B <- n * var(psi.means) #between variance est.
psi.w <- apply(psi, 1, "var") #within variances
W <- mean(psi.w) #within est.
v.hat <- W*(n-1)/n + (B/n) #upper variance est.
r.hat <- v.hat / W #G-R statistic
return(r.hat)
}
cauchy.chain <- function(sigma, N, x1){
x  <-  numeric(N)
x[1]  <- x1
k  <-  0
u  <-  runif(N)
for  (i  in  2:N)  {
xt  <-  x[i-1]
y  <-  rnorm(1,mean=xt,sd=sigma)
num <- f(y) * dnorm(xt, mean=y,sd = sigma)
den <- f(xt) * dnorm(y,mean=xt ,sd=sigma)
if  (u[i]  <= num/den ) x[i]  <-  y  else  {
x[i]  <-  xt
k  <-  k+1         #y  is  rejected
}
}
return(x)
}
set.seed(0)
sigma <- 0.2 #parameter of proposal distribution
k <- 4 #number of chains to generate
n <- 10000 #length of chains
b <- 1000 #burn-in length
#choose overdispersed initial values
x0 <- c(-1, -0.5, 0.5, 1)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- cauchy.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
#par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
#par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R")
abline(h=1.2, lty=2)
set.seed(0)
N <- 5000 #length of chain
burn <- 1000 #burn-in length
X <- matrix(0, N, 2) #the chain, a bivariate sample
a=5
b=4
n=20
x=1;y=0.5
bichain<-function(N=5000,burn=1000,a=5,b=4,n=20,x=1,y=0.5,plot=FALSE){
X <- matrix(0, N, 2)
X[1, ] <- c(x,y) #initialize
for (i in 2:N) {
X[i, 1] <- rbinom(1,size=n,prob=y)
x<-X[i,1]
X[i, 2] <- rbeta(n=1,shape1 = x+a,shape2 = n-x+b)
y<-X[i,2]
}
b <- burn + 1
x <- X[b:N, ]
if(plot == TRUE)
plot(x, main="", cex=.5, xlab="x",
ylab="y", ylim=range(x[,2]))
else
return(X)
}
bichain(plot=TRUE)
library(R2OpenBUGS)
library(MCMCglmm)
DATA1<- mcmc(data=cbind(bichain(x = 1,y=0.2,a=10,N=5000)))
DATA2<- mcmc(data=cbind(bichain(x= 10,y=0.8,a=10,N=5000)))
gelman.plot(x=c(mcmc.list(DATA1),mcmc.list(DATA2)))
ft<-function(a,n=1e7,eps=1e-9,plot="TRUE")
{ ## 输入参数：
## a为d维实值向量
## n为最大迭代次数,默认取1e7
## eps为精度,默认取1e-9
stopifnot(is.vector(a)) #当a不为向量时报错
d<-length(a)            #d为a的维度
an<-sqrt(sum(a^2))      #当a的模长为0时,输出0
if(an==0) return ((list(res=0,k=0)))
else{
## 注意到k!=gamma(k-1),k>=2时成立
## k=0,1时,k!=1,故将k=0,1情形单独列出
for(k in 0:1){
temp1<-(2*k+2)*log(an)+lgamma((d+1)/2)+lgamma(k+3/2)
temp2<-k*log(2)+log(2*k+1)+log(2*k+2)+lgamma(k+d/2+1)
temp<-exp(temp1-temp2)
if(temp<=eps) {
return(list(res=temp,k=k))
}
}
for(k in 2:n){
temp1<-(2*k+2)*log(an)+lgamma((d+1)/2)+lgamma(k+3/2)
temp2<-lgamma(k-1)+k*log(2)+log(2*k+1)+log(2*k+2)+lgamma(k+d/2+1)
temp<-exp(temp1-temp2)
if(temp<=eps) {
if(plot=="TRUE")
{ cat(c("d=",d,"\n"))
cat(c("the Euclidean norm of a=",sqrt(sum(a^2)),"\n"))
cat(c("k=",k,"\n"))
cat("converge\n")}
return(list(res=temp,k=k))
}
}
#for循环正常结束,次数说明迭代次数较少,可能需要增加n的初始值
cat("did not converge\n")
return(list(res=temp,k=k))
}
}
ff<-function(a,n=1e5,eps=1e-9)
{
stopifnot(is.vector(a))
d<-length(a)
res<-0
an<-sqrt(sum(a^2))
if(an==0) return (0)
else{
for(k in 0:1){
temp1<-(2*k+2)*log(an)+lgamma((d+1)/2)+lgamma(k+3/2)
temp2<-k*log(2)+log(2*k+1)+log(2*k+2)+lgamma(k+d/2+1)
temp<-exp(temp1-temp2)
res<-res+(-1)^k*temp
if(temp<=eps) {
cat(c("k=",k,"\n"))
cat("converge\n")
return(res)
}
}
for(k in 2:n){
temp1<-(2*k+2)*log(an)+lgamma((d+1)/2)+lgamma(k+3/2)
temp2<-lgamma(k-1)+k*log(2)+log(2*k+1)+log(2*k+2)+lgamma(k+d/2+1)
temp<-exp(temp1-temp2)
res<-res+(-1)^k*temp
if(temp<=eps) {
cat(c("k=",k,"\n"))
cat("converge\n")
return(res)
}
}
cat("did not converge\n")
return(res)
}
}
a<-seq(0,4,.01)
ff(a)
a<-c(1,2)
ff(a)
SS<-function(a,k){
stopifnot(k>1)
n<-length(a)
res<-numeric(n)
for(i in 1:n){
if(abs(a[i]^2-k-1)<1e-7) res[i]<-0
else{
temp<-sqrt(a[i]^2*k/(k+1-a[i]^2))
res[i]<-(1-pt(temp,df=k))
}
}
return(res)
}
for(k in c(4,25,100)){
aa<-seq(-sqrt(k),sqrt(k),1e-2)
plot(aa,SS(aa,k)-SS(aa,k-1),ylab="",type="l")
abline(h=0)
}
kk<-c(4:25,100,500,1000)
root<-matrix(0,nrow = length(kk),ncol = 3)
root[,1]<-kk
colnames(root)<-c("k","root_negative","root_positive")
for(i in  1: length(kk)){
dsa<-function(a){
return(SS(a,kk[i])-SS(a,kk[i]-1))
}
a<-seq(-sqrt(kk[i]),0,1e-3)
d1<-which.max(dsa(a))
d2<-which.min(dsa(a))
res<-uniroot(dsa, sort(a[c(d1,d2)]))
root[i,2]=unlist(res[1])
root[i,3]<-abs(root[i,2])
}
knitr::kable(root)
da<-c(0.54, 0.48, 0.33, 0.43, 1.00, 1.00, 0.91, 1.00, 0.21, 0.85)
k<-ifelse(da<1,da,0)
n<-length(da)
n_e<-n-sum(da<1)
estar<-function(lambda){
return(n_e*(1+lambda))
}
EM<-function(k,n,max.it=1e4,eps=1e-7)
{
i<-1
lambda1<-5
lambda2<-2
while(abs(lambda1-lambda2)>=eps){
lambda1<-lambda2
lambda2<-(sum(k)+estar(lambda=lambda2))/(n)
print(round(c(lambda2),5))
if(i == max.it) break
i<i+1
}
return(lambda2)
}
EM(k=k,n=n)
(n_e+sum(k))/(n-n_e)
set.seed(0)
trims <- c(0, 0.1, 0.2, 0.5)
x <- rcauchy(100)
lapply(trims, function(trim) mean(x, trim = trim))
lapply(trims, mean, x = x)
rsq <- function(mod) summary(mod)$r.squared
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)
mod<-lapply(formulas, lm,data=mtcars)
r2<-lapply(mod, rsq)
round(unlist(r2),3)
bootstraps <- lapply(1:10, function(i) {
rows <- sample(1:nrow(mtcars), rep = TRUE)
mtcars[rows, ]
})
mod<-lapply(bootstraps, lm,formula=mpg ~ disp )
r2<-lapply(mod, rsq)
round(unlist(r2),3)
set.seed(0)
df<-data.frame(replicate(6,sample(c(1:10),10,rep=T)))
round(vapply(df, sd,FUN.VALUE = double(1)),3)
set.seed(0)
df<-data.frame(replicate(6,sample(c(1:10),10,rep=T)),y=rep("a",10))
round(vapply(df[vapply(df, is.integer, FUN.VALUE = logical(1))]
, sd,FUN.VALUE = double(1)),3)
library(parallel)
nocore<-detectCores()-1
cl<-makeCluster(nocore)
mcsapply<-function(cl=makeCluster(detectCores()-1),X,FUN){
parallel::parLapply(cl, X, FUN)
}
mcsapply(cl, 1:4, function(x) x+3)
mcvapply<-function(cl=makeCluster(detectCores()-1),X,FUN,USE.NAMES =TRUE){
Y=X[sapply(X, function(x) typeof(x)==typeof(USE.NAMES))]
if(length(Y)==0) return("ERROR")
else(parLapply(cl, Y, FUN))
}
mcvapply(cl, 1:4, function(x) x+3,USE.NAMES = integer(1))
mcvapply(cl, 1:4, function(x) x+3,USE.NAMES = TRUE)
set.seed(0)
#library(Rcpp)
Rcpp::cppFunction(
'NumericMatrix gibbsC(int N) {
NumericMatrix mat(N, 2);
double x = 0, y = 0, a=5,b=4,n=20;
for(int i = 0; i < N; i++) {
x = rbinom(1,n,y)[0];
y = rbeta(1,x+a,n-x+b)[0];
mat(i, 0) = x;
mat(i, 1) = y;
}
return(mat);
}'
)
data<-gibbsC(1000)
plot(data)
Rcpp::cppFunction('NumericVector cunif(int n,double min,double max){
NumericVector x;
x=runif(n,min,max);
return(x);
}')
set.seed(0)
cc<-cunif(n=1000,min=-1,max=1)
rr<-runif(n=1000,min=-1,max=1)
qqplot(cc,rr)
#   library(microbenchmark)
ts <- microbenchmark::microbenchmark(cc<-cunif(n=1000,min=-1,max=1),
rr<-runif(n=1000,min=-1,max=1))
summary(ts)[,c(1,3,5,6)]
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
install.packages('../StatComp21019_1.0.tar.gz',repo=NULL)
devtools::build(vignettes=TRUE)
devtools::build(vignettes=TRUE)
install.packages('../StatComp21019_1.0.tar.gz',repo=NULL)
library(StatComp21019)
devtools::install_github("loseriser\StatComp21019")]()
devtools::install_github("loseriser\StatComp21019")]()
devtools::install_github("loseriser/StatComp21019")]()
install_github("loseriser\Statcom21019")
install_github("loseriser/Statcom21019")
devtools::install_github("loseriser/Statcom21019")
devtools::install_github("loseriser/Statcomp21019")
devtools::install_github("loseriser/Statcomp21019")
devtools::install_github("loseriser/Statcomp21019")
devtools::install_github("loseriser/Statcomp21019")
install.packages('../StatComp21019_1.0.tar.gz',repo=NULL)
detach("package:StatComp21019", unload = TRUE)
install.packages('../StatComp21019_1.0.tar.gz',repo=NULL)
devtools::build(vignettes=TRUE)
install.packages('../StatComp21019_1.0.tar.gz',repo=NULL)
devtools::install_github("loseriser/Statcomp21019")
devtools::install_github("loseriser/Statcomp21019")
